# ğŸš— **Tesla Model 3 Hybrid RAG Assistant**  
**AI & Automation Internship Selection Challenge â€” Option 1**

---

## âœ… **Task Chosen**
I selected **Option 1: Hybrid Support Bot (RAG System)** from the challenge instructions.  
This task requires building a Retrieval-Augmented Generation (RAG) assistant that answers questions strictly from a document â€” in this case, the **Tesla Model 3 Ownerâ€™s Manual** â€” with no hallucinations or external knowledge.

---

## ğŸ“˜ **Project Overview**
This project implements a fully offline, metadata-aware RAG system that:

- Parses the **Tesla Model 3 Ownerâ€™s Manual (PDF)**  
  https://www.tesla.com/ownersmanual/model3/en_us/Owners_Manual.pdf
- Extracts **chapters, headings, page numbers, and metadata**
- Cleans and chunks the manual for efficient retrieval  
- Embeds content using **nomic-embed-text** (via Ollama)
- Stores vectors inside a **persistent ChromaDB** database
- Retrieves relevant sections using **hybrid (vector + metadata) search**
- Builds a strict **grounded RAG prompt** with hallucination prevention
- Generates responses using **llama3.1:8b-instruct-q4_K_M** locally
- Provides a **CLI assistant** and a **Streamlit UI**

### â­ This project fulfills all requirements for **Option 1**.

---

## ğŸ“ **Project Structure**

hybrid_rag_bot/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (PDF stored locally, ignored in Git)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parsing/
â”‚   â”‚   â”œâ”€â”€ pdf_reader.py
â”‚   â”‚   â”œâ”€â”€ heading_extractor.py
â”‚   â”‚   â””â”€â”€ text_cleaner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â””â”€â”€ ingest.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ llama_client.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ rag_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ cli_query.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ types.py
â”‚       â””â”€â”€ config.py
â”‚
â”œâ”€â”€ chroma_db/                 # Persistent vector DB (ignored in Git)
â”‚
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ screenshots/
â”‚   â”‚   â”œâ”€â”€ Ingest_Screenshot1.png
â”‚   â”‚   â”œâ”€â”€ Ingest_Screenshot2.png
â”‚   â”‚   â”œâ”€â”€ Ingest_Screenshot3.png
â”‚   â”‚   â”œâ”€â”€ retriever_screenshot.png
â”‚   â”‚   â”œâ”€â”€ rag_pipeline_screenshot.png
â”‚   â”‚   â”œâ”€â”€ cli_screenshot.png
â”‚   â”‚   â”œâ”€â”€ streamlit_screenshot1.png
â”‚   â”‚   â”œâ”€â”€ streamlit_screenshot2.png
â”‚   â”‚   â””â”€â”€ streamlit_screenshot3.png
â”‚   â””â”€â”€ demo_video.mp4
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

### âš™ï¸ How to Set Up & Run the Project
#### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/YOUR_USERNAME/hybrid_rag_bot.git
cd hybrid_rag_bot

#### 2ï¸âƒ£ Create Environment
conda create -n ragbot python=3.10 -y
conda activate ragbot

#### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

#### 4ï¸âƒ£ Pull Required Models (Ollama)
ollama pull llama3.1
ollama pull nomic-embed-text

#### ğŸ“˜ Step 1 â€” Ingest the Manual

Converts the PDF â†’ cleaned text â†’ chunks â†’ embeddings â†’ Chroma vector store.

python -m src.ingestion.ingest

#### ğŸ” Step 2 â€” Test Retrieval
python -m src.retrieval.retriever

#### ğŸ¤– Step 3 â€” Run RAG Pipeline (CLI)
python -m src.pipeline.rag_pipeline

#### ğŸ–¥ï¸ Step 4 â€” Launch Streamlit Web Interface
streamlit run app/app.py

The UI includes:

Chat interface

Retrieved context preview

Latency metrics

Conversation memory

Optional chapter filter

### ğŸ“š Why These Libraries & Models?
- LangChain 2025

- Modern LCEL pipelines

- Clean modular RAG orchestration

- ChromaDB

- Fast, persistent local vector store

- PyMuPDF

- Accurate PDF parsing for structured manuals

- Ollama + Llama 3.1

- Fully offline inference

- No API cost

- High grounding accuracy

- nomic-embed-text

- High-quality embeddings designed for documents

- Streamlit

- Quick and interactive UI

#### ğŸ¥ Demo Video

(Add Loom or YouTube link here)
